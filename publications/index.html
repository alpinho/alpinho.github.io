<!DOCTYPE html> <html lang="en"> <head> <meta name="google-site-verification" content=""/> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Ana Luísa Pinho</title> <meta name="author" content="Ana Luísa Pinho"/> <meta name="description" content="Publications in reversed chronological order."/> <meta name="keywords" content="academic-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/css/all.min.css" integrity="sha384-h/hnnw1Bi4nbpD6kE7nYfCXzovi622sY5WBxww8ARKwpdLj5kUWjRuyiXaD1U2JT" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://alpinho.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Ana Luísa </span>Pinho</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Curriculum Vitae</a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">Selected Talks</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description">Publications in reversed chronological order.</p> </header> <article> <div class="publications"> <h2 class="year">2026</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Research Article</abbr></div> <div id="Aggarwal2026" class="col-sm-8"> <div class="title">Subject fingerprinting and task classification rely on distinct functional connectivity features</div> <div class="author"> Himanshu Aggarwal, Ana Fernanda Ponce, Swetha Shankar, Yasmin Mzayek, Agnés Pérez-Millan, <em>Ana Luísa Pinho</em>, Alexis Thual, and Bertrand Thirion</div> <div class="periodical"> <em>Brain Structure and Function</em> Jan 2026 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1007/s00429-025-03068-3" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>Functional connectivity (FC) measured by functional magnetic resonance imaging (fMRI) has been shown to be a marker of individual brain characteristics, and also to reflect cognitive tasks. However, it remains unclear how the choice of FC measures affects the encoding of both subject and task properties. We address this question using a high-quality deep-phenotyping dataset consisting of multiple naturalistic tasks (listening to a story, watching three different movies and playing a video game) and resting-state, while working on two classification problems: subject fingerprinting and task classification. We compare the performance of a combination of two FC measures and three covariance estimation methods. We then examine the similarity and subject specificity of FC across tasks and with structural connectivity (SC). We find that sparse partial correlation, obtained from the Graphical-Lasso estimator, performs best in subject identification tasks and is most similar to SC; it stands out as a marker of identity. In contrast, task information is better captured by Pearson correlation measures, as they account for distributed brain activity. Overall, we find that pairwise interactions captured by partial correlation are optimal for fingerprinting, while multi-way relationships underlying full correlation are an accurate marker of cognitive function.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Aggarwal2026</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Subject fingerprinting and task classification rely on distinct functional connectivity features}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Aggarwal, Himanshu and Ponce, Ana Fernanda and Shankar, Swetha and Mzayek, Yasmin and P{\'e}rez-Millan, Agn{\'e}s and Pinho, Ana Lu{\'i}sa and Thual, Alexis and Thirion, Bertrand}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Brain Structure and Function}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{231}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s00429-025-03068-3}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer Berlin Heidelberg Berlin/Heidelberg}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="Clarke2026" class="col-sm-8"> <div class="title">Girls just wanna have funds: a new Transparent Reporting Scale for evaluating grant data reporting from funding agencies</div> <div class="author"> Natasha Clarke, Abigail E. Licata, Soumaiya Imarraine, Thuy Dao, Ginevra Sperandio, <em>Ana Luísa Pinho</em>, Valentina Borghesani, Paola Mengotti, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Antonietta Gabriella Liuzzi, Doris Pischedda' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Front Comput Neurosci</em> Feb 2026 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.3389/fncom.2026.1765249" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>Introduction: Despite the increasing representation of women in scientific fields, disparities in research funding allocation remain. This inequity deprives talented women researchers of necessary resources, limiting the diversity of perspectives and ideas, and contributes to the “scissor-shaped curve” seen in neuroscience, where women leave before obtaining senior positions. Data transparency and comprehensive reporting of information on grant winners and applicants, as well as reporting of gender and other intersecting demographics and key metrics, are crucial to effectively evaluate funding equity. However, there is a lack of guidelines on which data funders should report. In this study, we aimed to investigate the transparency of neuroscience funders across Europe, focusing on the European Union, Schengen area, and the United Kingdom. Methods: To this end, we developed a Transparent Reporting Scale (TRS), composed of 15 items crucial to facilitate transparent and meaningful reporting, and searched for public data from funders in order to apply the scale and evaluate their transparency in data reporting. Across 32 countries and the European Union as a whole, we identified 39 funders, with 90% sharing publicly available data on funding results. Results: Using the TRS, five funders received a “gold” rating, eighteen a “silver” one, and thirteen a “bronze” rating. Scale scores were significantly correlated with the Gender Equality Index [p = 0.64, 95% CI (0.33, 0.83), p = 0.001] and gross domestic product of the countries where funders are based [p = 0.51, 95% CI (0.20, 0.74), p = 0.003], suggesting that collection and/or publication of funding data may reflect overall commitments to gender equity, and be limited due to resources. Data from only 29% of funders could be disaggregated for the neuroscience category specifically, indicating the difficulty in evaluating equity in our field. Discussion: We collated all available data into an Open Science Framework repository to enable data sharing and further analyses. The TRS can support funders in adopting transparent, standardized reporting practices in order to support evidence-based progress toward gender equity.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Clarke2026</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Clarke, Natasha and Licata, Abigail E. and Imarraine, Soumaiya and Dao, Thuy and Sperandio, Ginevra and Pinho, Ana Lu{\'i}sa and Borghesani, Valentina and Mengotti, Paola and Liuzzi, Antonietta Gabriella and Pischedda, Doris}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Girls just wanna have funds: a new Transparent Reporting Scale for evaluating grant data reporting from funding agencies}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Front Comput Neurosci}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{20}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1765249}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.3389/fncom.2026.1765249}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Software</abbr></div> <div id="nilearn_contributors_2025_17043133" class="col-sm-8"> <div class="title">nilearn</div> <div class="author"> Nilearn contributors, Ahmad Chamma, Aina Frau-Pascual, Alex Rothberg, Alexandre Abadie, Alexandre Abraham, Alexandre Gramfort, Alexandre Savio, and <span class="more-authors" title="click to view 160 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '160 more authors' ? 'Alexandre Cionca, Alexandre Sayal, Alexis Thual, Alisha Kodibagkar, Amadeus Kanaan, Ana Luísa Pinho, Anand Joshi, Andrés Hoyos Idrobo, Anne-Sophie Kieslinger, Anupriya Kumari, Ariel Rokem, Arthur Mensch, Aswin Vijayan, Audrey Duran, Ben Cipollini, Bertrand Thirion, Binh Nguyen, Caglar Cakan, Chris Gorgolewski, Chris Markiewicz, Christian Horea, Christian Gerloff, Christina Roßmanith, Colin Reininger, Connor Lane, Czarina Sy, Céline Delettre, Dan Gale, Daniel Gomez, Danilo Bzdok, David G Ellis, Demian Wassermann, Derek Pisner, Dimitri Papadopoulos Orfanos, Elizabeth DuPre, Elvis Dohmatob, Eric Larson, Evan Edmond, Fabian Pedregosa, Florent Pollet, Franz Liem, François Paugam, Gael Varoquaux, Gilles de Hollander, Greg Kiar, Greydon Gilmore, Guillaume Lemaitre, Gustav Magnusson, Hande Gözükan, Hao-Ting Wang, Himanshu Aggarwal, Ian Abenes, Idrissa Traore, Jake Vogel, Jan Margeta, Jaques Grobler, Jason Gors, Jason Kai, Javier Rasero, Jean Kossaifi, Jean-Rémi King, Jelle Roelof Dalenberg, Jeremy Lefort-Besnard, Jerome Dockes, Jerome-Alexis Chevalier, Johannes Wiesner, John T. Johnson, Jon Haitz Legarreta Gorrono, Jona Sassenhagen, Jordi Huguet, Joshua Teves, Julia Huntenburg, Julio A Peraza, Kamalakar Reddy Daddy, Kevin Sitek, Koen Helwegen, Konrad Wagstyl, Konstantin Shmelkov, Kshitij Chawla, Kun CHEN, Lee Newberg, Leonard Sasse, Loic Estève, Loic Tetrel, Luz Paz, Manon Pietrantoni, Martin Perez-Guevara, Martin Wegrzyn, Mathias Goncalves, Mathieu Dugré, Matthias Ekman, Matthieu Joulot, Maximilian Cosmo Sitter, Mehdi Rahim, Mia Zwally, Micha Burkhardt, Michael Eickenberg, Michael Hanke, Michael Notter, Michael Waskom, Michelle Wang, Mohammad Torabi, Moritz Boos, Mudassir Chapra, Myeong Seop Song, Natasha Clarke, Neelay Shah, Nicolas Gensollen, Nikhil Krish, Oliver Warrington, Oscar Esteban, Patrick Sadil, Paul Bogdan, Paul Reiners, Paula Sanz-Leon, Peer Herholz, Philippe Gervais, Pierre Bellec, Pierre Glaser, Pierre-Louis Barbarant, Pierre-Olivier Quirion, Pradeep Reddy Raamana, Prakhar Jain, Rahul Brito, Raphael Meudec, Robert Luke, Robert Williamson, Roberto Guidotti, Rohan Thomas Jepegnanam, Ronald Phlypo, Ryan Hammonds, Rémi Gau, Sachin Patalasingh, Sage Hahn, Salma Bougacha, Sam Buck Johnson, Sami Jawhar, Simon Steinkamp, Sin Kim, Sourav Singh, Steven Meisler, Suramya Pokharel, Sylvain Lan, Sylvain Takerkart, Tamer Gezici, Tarun Samanta, Taylor Salo, Tharun K, Thiti Premrudeepreechacharn, Thomas Bazeille, Tom Vanasse, Vasco Diogo, Victoria Shevchenko, Vincent Michel, Virgile Fritsch, Yaroslav Halchenko, Yasmin Mzayek, Yichun Huang, Zvi Baratz, Óscar Nájera' : '160 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">160 more authors</span> </div> <div class="periodical"> Sep 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@software</span><span class="p">{</span><span class="nl">nilearn_contributors_2025_17043133</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{contributors, Nilearn and Chamma, Ahmad and Frau-Pascual, Aina and Rothberg, Alex and Abadie, Alexandre and Abraham, Alexandre and Gramfort, Alexandre and Savio, Alexandre and Cionca, Alexandre and Sayal, Alexandre and Thual, Alexis and Kodibagkar, Alisha and Kanaan, Amadeus and Pinho, Ana Lu{\'i}sa and Joshi, Anand and Idrobo, Andrés Hoyos and Kieslinger, Anne-Sophie and Kumari, Anupriya and Rokem, Ariel and Mensch, Arthur and Vijayan, Aswin and Duran, Audrey and Cipollini, Ben and Thirion, Bertrand and Nguyen, Binh and Cakan, Caglar and Gorgolewski, Chris and Markiewicz, Chris and Horea, Christian and Gerloff, Christian and Roßmanith, Christina and Reininger, Colin and Lane, Connor and Sy, Czarina and Delettre, Céline and Gale, Dan and Gomez, Daniel and Bzdok, Danilo and Ellis, David G and Wassermann, Demian and Pisner, Derek and Orfanos, Dimitri Papadopoulos and DuPre, Elizabeth and Dohmatob, Elvis and Larson, Eric and Edmond, Evan and Pedregosa, Fabian and Pollet, Florent and Liem, Franz and Paugam, François and Varoquaux, Gael and Hollander, Gilles de and Kiar, Greg and Gilmore, Greydon and Lemaitre, Guillaume and Magnusson, Gustav and Gözükan, Hande and Wang, Hao-Ting and Aggarwal, Himanshu and Abenes, Ian and Traore, Idrissa and Vogel, Jake and Margeta, Jan and Grobler, Jaques and Gors, Jason and Kai, Jason and Rasero, Javier and Kossaifi, Jean and King, Jean-Rémi and Dalenberg, Jelle Roelof and Lefort-Besnard, Jeremy and Dockes, Jerome and Chevalier, Jerome-Alexis and Wiesner, Johannes and Johnson, John T. and Gorrono, Jon Haitz Legarreta and Sassenhagen, Jona and Huguet, Jordi and Teves, Joshua and Huntenburg, Julia and Peraza, Julio A and Daddy, Kamalakar Reddy and Sitek, Kevin and Helwegen, Koen and Wagstyl, Konrad and Shmelkov, Konstantin and Chawla, Kshitij and CHEN, Kun and Newberg, Lee and Sasse, Leonard and Estève, Loic and Tetrel, Loic and Paz, Luz and Pietrantoni, Manon and Perez-Guevara, Martin and Wegrzyn, Martin and Goncalves, Mathias and Dugré, Mathieu and Ekman, Matthias and Joulot, Matthieu and Sitter, Maximilian Cosmo and Rahim, Mehdi and Zwally, Mia and Burkhardt, Micha and Eickenberg, Michael and Hanke, Michael and Notter, Michael and Waskom, Michael and Wang, Michelle and Torabi, Mohammad and Boos, Moritz and Chapra, Mudassir and Song, Myeong Seop and Clarke, Natasha and Shah, Neelay and Gensollen, Nicolas and Krish, Nikhil and Warrington, Oliver and Esteban, Oscar and Sadil, Patrick and Bogdan, Paul and Reiners, Paul and Sanz-Leon, Paula and Herholz, Peer and Gervais, Philippe and Bellec, Pierre and Glaser, Pierre and Barbarant, Pierre-Louis and Quirion, Pierre-Olivier and Raamana, Pradeep Reddy and Jain, Prakhar and Brito, Rahul and Meudec, Raphael and Luke, Robert and Williamson, Robert and Guidotti, Roberto and Jepegnanam, Rohan Thomas and Phlypo, Ronald and Hammonds, Ryan and Gau, Rémi and Patalasingh, Sachin and Hahn, Sage and Bougacha, Salma and Johnson, Sam Buck and Jawhar, Sami and Steinkamp, Simon and Kim, Sin and Singh, Sourav and Meisler, Steven and Pokharel, Suramya and Lan, Sylvain and Takerkart, Sylvain and Gezici, Tamer and Samanta, Tarun and Salo, Taylor and K, Tharun and Premrudeepreechacharn, Thiti and Bazeille, Thomas and Vanasse, Tom and Diogo, Vasco and Shevchenko, Victoria and Michel, Vincent and Fritsch, Virgile and Halchenko, Yaroslav and Mzayek, Yasmin and Huang, Yichun and Baratz, Zvi and Nájera, Óscar}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{nilearn}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Zenodo}</span><span class="p">,</span>
  <span class="na">version</span> <span class="p">=</span> <span class="s">{0.12.1}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5281/zenodo.17043133}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.5281/zenodo.17043133}</span><span class="p">,</span>
  <span class="na">swhid</span> <span class="p">=</span> <span class="s">{swh:1:dir:542cbb4bd11b6ab8be777d75dabfe19748e66bf0
                     ;origin=https://doi.org/10.5281/zenodo.8397156;vis
                     it=swh:1:snp:93592dedcc8d6ad5431ec624eed7f4533f95f
                     7e4;anchor=swh:1:rel:62b0eb4dd34e5b77f30f903c8e00b
                     1b035a0a3ed;path=nilearn-nilearn-4c76adf
                    }</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Research Article</abbr></div> <div id="Kong2024" class="col-sm-8"> <div class="title">A network correspondence toolbox for quantitative evaluation of novel neuroimaging results</div> <div class="author"> Ru Q Kong, R. Nathan Spreng, Aihuiping Xue, Richard Betzel, Jessica R Cohen, Jessica Damoiseaux, Felipe De Brigard, Simon B Eickhoff, and <span class="more-authors" title="click to view 14 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '14 more authors' ? 'Alex Fornito, Caterina Gratton, Evan M Gordon, Avram J Holmes, Angela R Laird, Linda Larson-Prior, Lisa D Nickerson, Ana Luísa Pinho, Adeel Razi, Sepideh Sadaghiani, James Shine, Anastasia Yendiki, B.T. Thomas Yeo, Lucina Q Uddin' : '14 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">14 more authors</span> </div> <div class="periodical"> <em>Nat Commun</em> Mar 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1038/s41467-025-58176-9" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://www.nature.com/articles/s41467-025-58176-9.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The brain can be decomposed into large-scale functional networks, but the specific spatial topographies of these networks and the names used to describe them vary across studies. Such discordance has hampered interpretation and convergence of research findings across the field. We have developed the Network Correspondence Toolbox (NCT) to permit researchers to examine and report spatial correspondence between their novel neuroimaging results and multiple widely used functional brain atlases. We provide several exemplar demonstrations to illustrate how researchers can use the NCT to report their own findings. The NCT provides a convenient means for computing Dice coefficients with spin test permutations to determine the magnitude and statistical significance of correspondence among user-defined maps and existing atlas labels. The adoption of the NCT will make it easier for network neuroscience researchers to report their findings in a standardized manner, thus aiding reproducibility and facilitating comparisons between studies to produce interdisciplinary insights.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Kong2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kong, Ru Q and Spreng, R. Nathan and Xue, Aihuiping and Betzel, Richard and Cohen, Jessica R and Damoiseaux, Jessica and De Brigard, Felipe and Eickhoff, Simon B and Fornito, Alex and Gratton, Caterina and Gordon, Evan M and Holmes, Avram J and Laird, Angela R and Larson-Prior, Linda and Nickerson, Lisa D and Pinho, Ana Lu{\'i}sa and Razi, Adeel and Sadaghiani, Sepideh and Shine, James and Yendiki, Anastasia and Yeo, B.T. Thomas and Uddin, Lucina Q}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A network correspondence toolbox for quantitative evaluation of novel neuroimaging results}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1038/s41467-025-58176-9}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nat Commun}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Research Article</abbr></div> <div id="Zhi2025" class="col-sm-8"> <div class="title">A hierarchical Bayesian brain parcellation framework for fusion of functional imaging datasets</div> <div class="author"> Da Zhi, Ladan Shahshahani, Caroline Nettekoven, <em>Ana Luísa Pinho</em>, Danilo Bzdok, and Jörn Diedrichsen</div> <div class="periodical"> <em>Imaging Neuroscience</em> Jan 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1162/imag_a_00408" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://direct.mit.edu/imag/article-pdf/doi/10.1162/imag_a_00408/2482835/imag_a_00408.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Different task-based and resting-state imaging datasets provide complementary information about the organization of the human brain. Brain parcellations based on single datasets will, therefore, be biased toward the particular type of information present in each dataset. To overcome this limitation, we propose here a hierarchical Bayesian framework that can learn a probabilistic brain parcellation across numerous task-based and resting-state datasets, exploiting their combined strengths. The framework is partitioned into a spatial arrangement model that defines the probability of each voxel belonging to a specific parcel (the probabilistic group atlas), and a set of dataset-specific emission models that define the probability of the observed data given the parcel of the voxel. Using the human cerebellum as an example, we show that the framework optimally combines information from different datasets to achieve a new population-based atlas that outperforms atlases based on single datasets. Furthermore, we demonstrate that using only 10 min of individual data, the framework is able to generate individual brain parcellations that outperform group atlases.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Zhi2025</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhi, Da and Shahshahani, Ladan and Nettekoven, Caroline and Pinho, Ana Lu{\'i}sa and Bzdok, Danilo and Diedrichsen, J{\"o}rn}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A hierarchical Bayesian brain parcellation framework for fusion of functional imaging datasets}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1162/imag_a_00408}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Imaging Neuroscience}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Proceedings Paper</abbr></div> <div id="Moia2024" class="col-sm-8"> <div class="title">Proceedings of the OHBM Brainhack 2022</div> <div class="author"> Stefano Moia, Hao-Ting Wang, Anibal S. Heinsfeld, Dorota Jarecka, Yu Fang Yang, Stephan Heunis, Michele Svanera, Benjamin De Leener, and <span class="more-authors" title="click to view 78 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '78 more authors' ? 'Andrea Gondová, Sin Kim, Arshitha Basavaraj, Johanna M. M. Bayer, Roza G. Bayrak, Pierre-Louis Bazin, Isil Poyraz Bilgin, Steffen Bollmann, Daniel Borek, Valentina Borghesani, Trang Cao, Gang Chen, Alejandro de La Vega, Sebastian Dresbach, Philipp Ehses, Jan Ernsting, Inês Esteves, Oscar Ferrante, Kelly G. Garner, Rémi Gau, Elodie Germani, Tara Ghafari, Satrajit S. Ghosh, Sarah E. Goodale, Cassandra D. Gould Van Praag, Samuel Guay, Omer Faruk Gulban, Yaroslav O. Halchenko, Michael Hanke, Peer Herholz, Katja Heuer, Felix Hoffstaedter, Ruoqi Huang, Renzo Huber, Ole Jensen, Kan Keeratimahat, Julian Q. Kosciessa, Sladjana Lukic, Neville Magielse, Christopher J. Markiewicz, Caroline G. Martin, Camille Maumet, Anna Menacher, Jeff Mentch, Christian Mönch, Shammi More, Leonardo Muller, Leonardo Muller-Rodriguez, Samuel A. Nastase, Eliana Nicolaisen-Sobesky, Dylan M. Nielson, Christopher R. Nolan, François Paugam, Pedro Pinheiro-Chagas, Ana Luísa Pinho, Alessandra Pizzuti, Benjamin Poldrack, Benedikt A. Poser, Roberta Rocca, Jacob Sanz-Robinson, Kelvin Sarink, Kevin R Sitek, Nadine Spychala, Rüdiger Stirnberg, Michal Szczepanik, Mohammad Torabi, Roberto Toro, Sebastian G. W. Urchs, Sofie L. Valk, Adina S Wagner, Laura K. Waite, Alexander Q. Waite, Lea Waller, Tyler J. Wishard, Jianxiao Wu, Yuchen Zhou, Janine D. Bijsterbosch, The Physiopy Community' : '78 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">78 more authors</span> </div> <div class="periodical"> <em>Apert Neuro</em> Feb 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://inria.hal.science/hal-04478342/file/OHBM-Brainhack-2022.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>OHBM Brainhack 2022 took place in June 2022. The first hybrid OHBM hackathon, it had an in-person component taking place in Glasgow and three hubs around the globe to improve inclusivity and fit as many timezones as possible. In the buzzing setting of the Queen Margaret Union and of the virtual platform, 23 projects were presented after development. Following are the reports of 14 of those, as well as a recapitulation of the organisation of the event.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Moia2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Proceedings of the OHBM Brainhack 2022}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Moia, Stefano and Wang, Hao-Ting and Heinsfeld, Anibal S. and Jarecka, Dorota and Yang, Yu Fang and Heunis, Stephan and Svanera, Michele and Leener, Benjamin De and Gondov{\'a}, Andrea and Kim, Sin and Basavaraj, Arshitha and Bayer, Johanna M. M. and Bayrak, Roza G. and Bazin, Pierre-Louis and Bilgin, Isil Poyraz and Bollmann, Steffen and Borek, Daniel and Borghesani, Valentina and Cao, Trang and Chen, Gang and Vega, Alejandro de La and Dresbach, Sebastian and Ehses, Philipp and Ernsting, Jan and Esteves, In{\^e}s and Ferrante, Oscar and Garner, Kelly G. and Gau, R{\'e}mi and Germani, Elodie and Ghafari, Tara and Ghosh, Satrajit S. and Goodale, Sarah E. and Praag, Cassandra D. Gould Van and Guay, Samuel and Gulban, Omer Faruk and Halchenko, Yaroslav O. and Hanke, Michael and Herholz, Peer and Heuer, Katja and Hoffstaedter, Felix and Huang, Ruoqi and Huber, Renzo and Jensen, Ole and Keeratimahat, Kan and Kosciessa, Julian Q. and Lukic, Sladjana and Magielse, Neville and Markiewicz, Christopher J. and Martin, Caroline G. and Maumet, Camille and Menacher, Anna and Mentch, Jeff and M{\"o}nch, Christian and More, Shammi and Muller, Leonardo and Muller-Rodriguez, Leonardo and Nastase, Samuel A. and Nicolaisen-Sobesky, Eliana and Nielson, Dylan M. and Nolan, Christopher R. and Paugam, Fran{\c c}ois and Pinheiro-Chagas, Pedro and Pinho, Ana Lu{\'i}sa and Pizzuti, Alessandra and Poldrack, Benjamin and Poser, Benedikt A. and Rocca, Roberta and Sanz-Robinson, Jacob and Sarink, Kelvin and Sitek, Kevin R and Spychala, Nadine and Stirnberg, R{\"u}diger and Szczepanik, Michal and Torabi, Mohammad and Toro, Roberto and Urchs, Sebastian G. W. and Valk, Sofie L. and Wagner, Adina S and Waite, Laura K. and Waite, Alexander Q. and Waller, Lea and Wishard, Tyler J. and Wu, Jianxiao and Zhou, Yuchen and Bijsterbosch, Janine D. and Community, The Physiopy}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Apert Neuro}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.52294/001c.92760}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.52294/001c.92760}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-04478342}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Research Article</abbr></div> <div id="Nettekoven2024" class="col-sm-8"> <div class="title">A hierarchical atlas of the human cerebellum for functional precision mapping</div> <div class="author"> Caroline Nettekoven, Da Zhi, Ladan Shahshahani, <em>Ana Luísa Pinho</em>, Noam Saadon-Grosman, Randy Lee Buckner, and Jörn Diedrichsen</div> <div class="periodical"> <em>Nat Commun</em> Sep 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1038/s41467-024-52371-w" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://www.nature.com/articles/s41467-024-52371-w.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The human cerebellum is activated by a wide variety of cognitive and motor tasks. Previous functional atlases have relied on single task-based or resting-state fMRI datasets. Here, we present a functional atlas that integrates information from seven large-scale datasets, outperforming existing group atlases. The atlas has three further advantages. First, the atlas allows for precision mapping in individuals: the integration of the probabilistic group atlas with an individual localizer scan results in a marked improvement in prediction of individual boundaries. Second, we provide both asymmetric and symmetric versions of the atlas. The symmetric version, which is obtained by constraining the boundaries to be the same across hemispheres, is especially useful in studying functional lateralization. Finally, the regions are hierarchically organized across three levels, allowing analyses at the appropriate level of granularity. Overall, the present atlas is an important resource for the study of the interdigitated functional organization of the human cerebellum in health and disease.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Nettekoven2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nettekoven, Caroline and Zhi, Da and Shahshahani, Ladan and Pinho, Ana Lu{\'i}sa and Saadon-Grosman, Noam and Buckner, Randy Lee and Diedrichsen, J{\"o}rn}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A hierarchical atlas of the human cerebellum for functional precision mapping}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1038/s41467-024-52371-w}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Nature Portfolio}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8376}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nat Commun}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Data Descriptor</abbr></div> <div id="Pinho2024a" class="col-sm-8"> <div class="title">Individual Brain Charting dataset extension, third release for movie watching and retinotopy data</div> <div class="author"> <em>Ana Luísa Pinho</em>, Hugo Richard, Ana Fernanda Ponce, Michael Eickenberg, Alexis Amadon, Elvis Dohmatob, Isabelle Denghien, Juan Jesús Torre, and <span class="more-authors" title="click to view 18 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '18 more authors' ? 'Swetha Shankar, Himanshu Aggarwal, Alexis Thual, Thomas Chapalain, Chantal Ginisty, Séverine Becuwe-Desmidt, Séverine Roger, Yann Lecomte, Valérie Berland, Laurence Laurier, Véronique Joly-Testault, Gaëlle Médiouni-Cloarec, Christine Doublé, Bernadette Martins, Gaël Varoquaux, Stanislas Dehaene, Lucie Hertz-Pannier, Bertrand Thirion' : '18 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">18 more authors</span> </div> <div class="periodical"> <em>Sci Data</em> Jun 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1038/s41597-024-03390-1" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://www.nature.com/articles/s41597-024-03390-1.epdf?sharing_token=jLeD6QxFB2cdJNq566MT8dRgN0jAjWel9jnR3ZoTv0PHXFsAwXPIyB4Yay0BgxbcgJ_PeaJrDzmCddQJZrF7XHiBjOrt5i5vCd3nowyekkS11BvM4Y2-_I4FSYL8F9JFcxU-0hvVMSOy16_EpaTQ3qMXikhFPavxjmL8CSX_5lQ%3D" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The Individual Brain Charting (IBC) is a multi-task functional Magnetic Resonance Imaging dataset acquired at high spatialresolution, which is intended to facilitate the cognitive mapping of the human brain. It consists in the deep phenotyping of twelve individuals in a fixed environment, covering a broad range of psychological domains that allows, in turn, the investigation of atlasing techniques in functional neuroimaging. Here, we present the inclusion of task data from both naturalistic stimuli and trial-based designs, to uncover core structures of brain activation. We rely on the Fast Shared Response Model (FastSRM): an analytical tool that provides a data-driven solution to model naturalistic stimuli, typically containing many features. We show that data from left-out runs can be reconstructed using FastSRM, thus enabling the extraction of functional networks pertaining to vision, audio and language systems. We also present an in-depth study of the topographic organization of the visual system through a retinotopy task. IBC is open access: source plus derivatives imaging data and meta-data are available in public repositories.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Pinho2024a</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Individual Brain Charting dataset extension, third release for movie watching and retinotopy data}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pinho, Ana Lu{\'i}sa and Richard, Hugo and Ponce, Ana Fernanda and Eickenberg, Michael and Amadon, Alexis and Dohmatob, Elvis and Denghien, Isabelle and Torre, Juan Jes{\'u}s and Shankar, Swetha and Aggarwal, Himanshu and Thual, Alexis and Chapalain, Thomas and Ginisty, Chantal and Becuwe-Desmidt, S{\'e}verine and Roger, S{\'e}verine and Lecomte, Yann and Berland, Val{\'e}rie and Laurier, Laurence and Joly-Testault, V{\'e}ronique and M{\'e}diouni-Cloarec, Ga{\"e}lle and Doubl{\'e}, Christine and Martins, Bernadette and Varoquaux, Ga{\"e}l and Dehaene, Stanislas and Hertz-Pannier, Lucie and Thirion, Bertrand}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{Sci Data}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{590}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/s41597-024-03390-1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Conference Paper</abbr></div> <div id="Pinho2024b" class="col-sm-8"> <div class="title">Individual brain parcellations for cognitive mapping obtained from a hierarchical Bayesian framework.</div> <div class="author"> <em>Ana Luísa Pinho</em>, Jennifer Yoon, and Jörn Diedrichsen</div> <div class="periodical"> Jun 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://2024.ccneuro.org/poster/?id=265" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://2024.ccneuro.org/pdf/440_Paper_authored_CCN2024_conference_paper_iparcel.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>In recent years, individual brain parcellations have become increasingly popular in human brain imaging as they provide better precision for functional localization than population-based atlases. Yet, often, there is only very little individual data available to define individual regions. Here, we exploit a Hierarchical Bayesian Parcellation (HBP) scheme to derive subject-specific parcellations extracted from a limited amount of individual task data and evaluate its performance using the Distance-Controlled Boundary Coefficient. We compare the HBP performance with Dual Regression and Dictionary Learning, two data-driven methods commonly used on resting-state and task-based data. In particular, we demonstrate that the Bayesian integration of individual data with a group prior—inferred from a large deep-behavioral phenotyping resource—provides substantial advantages in defining individual regions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">Pinho2024b</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pinho, Ana Lu{\'i}sa and Yoon, Jennifer and Diedrichsen, J{\"o}rn}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Individual brain parcellations for cognitive mapping obtained from a hierarchical Bayesian framework.}</span><span class="p">,</span>
  <span class="na">howpublished</span> <span class="p">=</span> <span class="s">{CCN2024 - Conference on Cognitive Computational Neuroscience}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Boston, USA}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Research Article</abbr></div> <div id="Thirion2024" class="col-sm-8"> <div class="title">Should one go for individual-or group-level brain parcellations? A deep-phenotyping benchmark</div> <div class="author"> Bertrand Thirion, Himanshu Aggarwal, Ana Fernanda Ponce, <em>Ana Luísa Pinho</em>, and Alexis Thual</div> <div class="periodical"> <em>Brain Struct Funct</em> Jan 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1007/s00429-023-02723-x" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://inria.hal.science/hal-04331402/document" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The analysis and understanding of brain characteristics often require considering region-level information rather than voxel-sampled data. Subject-specific parcellations have been put forward in recent years, as they can adapt to individual brain organization and thus offer more accurate individual summaries than standard atlases. However, the price to pay for adaptability is the lack of group-level consistency of the data representation. Here, we investigate whether the good representations brought by individualized models are merely an effect of circular analysis, in which individual brain features are better represented by subject-specific summaries, or whether this carries over to new individuals, i.e., whether one can actually adapt an existing parcellation to new individuals and still obtain good summaries in these individuals. For this, we adapt a dictionary-learning method to produce brain parcellations. We use it on a deep-phenotyping dataset to assess quantitatively the patterns of activity obtained under naturalistic and controlled-task-based settings. We show that the benefits of individual parcellations are substantial, but that they vary a lot across brain systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Thirion2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Should one go for individual-or group-level brain parcellations? A deep-phenotyping benchmark}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Thirion, Bertrand and Aggarwal, Himanshu and Ponce, Ana Fernanda and Pinho, Ana Lu{\'i}sa and Thual, Alexis}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Brain Struct Funct}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{229}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{161--181}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Perspective</abbr></div> <div id="Uddin2023" class="col-sm-8"> <div class="title">Controversies and progress on standardization of large-scale brain network nomenclature</div> <div class="author"> Lucina Q. Uddin, Richard F. Betzel, Jessica R. Cohen, Jessica S. Damoiseaux, Felipe De Brigard, Simon B. Eickhoff, Alex Fornito, Caterina Gratton, and <span class="more-authors" title="click to view 14 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '14 more authors' ? 'Evan M. Gordon, Angela R. Laird, Linda Larson-Prior, A. Randal McIntosh, Lisa D. Nickerson, Luiz Pessoa, Ana Luísa Pinho, Russell A. Poldrack, Adeel Razi, Sepideh Sadaghiani, James M. Shine, Anastasia Yendiki, B. T. Thomas Yeo, R. Nathan Spreng' : '14 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">14 more authors</span> </div> <div class="periodical"> <em>Netw Neurosci</em> May 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1162/netn_a_00323" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://direct.mit.edu/netn/article-pdf/doi/10.1162/netn_a_00323/2104530/netn_a_00323.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The idea that the brain is composed of multiple large-scale networks has steadily gained traction over the past decade. Still, the field has not yet reached consensus on key issues regarding terminology. The Workgroup for HArmonized Taxonomy of NETworks (WHATNET) was formed in 2020 as an Organization for Human Brain Mapping (OHBM)-endorsed best practices committee to provide concrete recommendations and reporting guidelines for the scientific community. WHATNET members engaged in regular discussions, conducted a survey to catalog current practices in large-scale brain network nomenclature, identified barriers to progress, and brainstormed tools that could be developed to help standardize reporting in future studies. Here we summarize these activities and provide important considerations and initial recommendations for the network neuroscience community, noting open questions and controversies that require further empirical and theoretical investigation.Progress in scientific disciplines is accompanied by standardization of terminology. Network neuroscience, at the level of macro-scale organization of the brain, is beginning to confront the challenges associated with developing a taxonomy of its fundamental explanatory constructs. The Workgroup for HArmonized Taxonomy of NETworks (WHATNET) was formed in 2020 as an Organization for Human Brain Mapping (OHBM)-endorsed best practices committee to provide recommendations on points of consensus, identify open questions, and highlight areas of ongoing debate in the service of moving the field towards standardized reporting of network neuroscience results. The committee conducted a survey to catalog current practices in large-scale brain network nomenclature. A few well-known network names (e.g., default mode network) dominated responses to the survey, and a number of illuminating points of disagreement emerged. We summarize survey results and provide initial considerations and recommendations from the workgroup. This perspective piece includes a selective review of challenges to this enterprise, including 1) network scale, resolution, and hierarchies; 2) inter-individual variability of networks; 3) dynamics and non-stationarity of networks; 4) consideration of network affiliations of subcortical structures; and 5) consideration of multi-modal information. We close with minimal reporting guidelines for the cognitive and network neuroscience communities to adopt.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Uddin2023</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Uddin, Lucina Q. and Betzel, Richard F. and Cohen, Jessica R. and Damoiseaux, Jessica S. and De Brigard, Felipe and Eickhoff, Simon B. and Fornito, Alex and Gratton, Caterina and Gordon, Evan M. and Laird, Angela R. and Larson-Prior, Linda and McIntosh, A. Randal and Nickerson, Lisa D. and Pessoa, Luiz and Pinho, Ana Luísa and Poldrack, Russell A. and Razi, Adeel and Sadaghiani, Sepideh and Shine, James M. and Yendiki, Anastasia and Yeo, B. T. Thomas and Spreng, R. Nathan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Controversies and progress on standardization of large-scale brain network nomenclature}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Netw Neurosci}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-111}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2472-1751}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1162/netn_a_00323}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Research Article</abbr></div> <div id="Dohmatob2021" class="col-sm-8"> <div class="title">Brain topography beyond parcellations: Local gradients of functional maps</div> <div class="author"> Elvis Dohmatob, Hugo Richard, <em>Ana Luísa Pinho</em>, and Bertrand Thirion</div> <div class="periodical"> <em>Neuroimage</em> Apr 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1016/j.neuroimage.2020.117706" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://reader.elsevier.com/reader/sd/pii/S1053811920311915?token=B9B66A2D6A49AD7EA39C09735B2FE8327E84ABA475EA1ACA7D9F5282938B279BCDFB3DE7094E2E823F9D9AE37F89869A&amp;originRegion=us-east-1&amp;originCreation=20221011024110" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Functional neuroimaging provides the unique opportunity to characterize brain regions based on their response to tasks or ongoing activity. As such, it holds the premise to capture brain spatial organization. Yet, the conceptual framework to describe this organization has remained elusive: on the one hand, parcellations build implicitly on a piecewise constant organization, i.e. flat regions separated by sharp boundaries; on the other hand, the recently popularized concept of functional gradient hints instead at a smooth structure. Noting that both views converge to a topographic scheme that pieces together local variations of functional features, we perform a quantitative assessment of local gradient-based models. Using as a driving case the prediction of functional Magnetic Resonance Imaging (fMRI) data —concretely, the prediction of task-fMRI from rest-fMRI maps across subjects— we develop a parcel-wise linear regression model based on a dictionary of reference topographies. Our method uses multiple random parcellations —as opposed to a single fixed parcellation— and aggregates estimates across these parcellations to predict functional features in left-out subjects. Our experiments demonstrate the existence of an optimal cardinality of the parcellation to capture local gradients of functional maps.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Dohmatob2021</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Brain topography beyond parcellations: Local gradients of functional maps}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Neuroimage}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{229}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{117706}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1053-8119}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.neuroimage.2020.117706}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1053811920311915}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dohmatob, Elvis and Richard, Hugo and Pinho, Ana Lu{\'i}sa and Thirion, Bertrand}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Parcellation, Functional mapping, Prediction, Model selection, Functional gradients}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Research Article</abbr></div> <div id="Levitis2021" class="col-sm-8"> <div class="title">Centering inclusivity in the design of online conferences—An OHBM–Open Science perspective</div> <div class="author"> Elizabeth Levitis, Cassandra D Gould van Praag, Rémi Gau, Stephan Heunis, Elizabeth DuPre, Gregory Kiar, Katherine L Bottenhorn, Tristan Glatard, and <span class="more-authors" title="click to view 102 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '102 more authors' ? 'Aki Nikolaidis, Kirstie Jane Whitaker, Matteo Mancini, Guiomar Niso, Soroosh Afyouni, Eva Alonso-Ortiz, Stefan Appelhoff, Aurina Arnatkeviciute, Selim Melvin Atay, Tibor Auer, Giulia Baracchini, Johanna M M Bayer, Michael J S Beauvais, Janine D Bijsterbosch, Isil P Bilgin, Saskia Bollmann, Steffen Bollmann, Rotem Botvinik-Nezer, Molly G Bright, Vince D Calhoun, Xiao Chen, Sidhant Chopra, Hu Chuan-Peng, Thomas G Close, Savannah L Cookson, R Cameron Craddock, Alejandro De La Vega, Benjamin De Leener, Damion V Demeter, Paola Di Maio, Erin W Dickie, Simon B Eickhoff, Oscar Esteban, Karolina Finc, Matteo Frigo, Saampras Ganesan, Melanie Ganz, Kelly G Garner, Eduardo A Garza-Villarreal, Gabriel Gonzalez-Escamilla, Rohit Goswami, John D Griffiths, Tijl Grootswagers, Samuel Guay, Olivia Guest, Daniel A Handwerker, Peer Herholz, Katja Heuer, Dorien C Huijser, Vittorio Iacovella, Michael J E Joseph, Agah Karakuzu, David B Keator, Xenia Kobeleva, Manoj Kumar, Angela R Laird, Linda J Larson-Prior, Alexandra Lautarescu, Alberto Lazari, Jon Haitz Legarreta, Xue-Ying Li, Jinglei Lv, Sina Mansour L., David Meunier, Dustin Moraczewski, Tulika Nandi, Samuel A Nastase, Matthias Nau, Stephanie Noble, Martin Norgaard, Johnes Obungoloch, Robert Oostenveld, Edwina R Orchard, Ana Luísa Pinho, Russell A Poldrack, Anqi Qiu, Pradeep Reddy Raamana, Ariel Rokem, Saige Rutherford, Malvika Sharan, Thomas B Shaw, Warda T Syeda, Meghan M Testerman, Roberto Toro, Sofie L Valk, Sofie Van Den Bossche, Gaël Varoquaux, František Váša, Michele Veldsman, Jakub Vohryzek, Adina S Wagner, Reubs J Walsh, Tonya White, Fu-Te Wong, Xihe Xie, Chao-Gan Yan, Yu-Fang Yang, Yohan Yee, Gaston E Zanitti, Ana E Van Gulick, Eugene Duff, Camille Maumet' : '102 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">102 more authors</span> </div> <div class="periodical"> <em>Gigascience</em> Aug 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1093/gigascience/giab051" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://academic.oup.com/gigascience/article-pdf/10/8/giab051/39810945/giab051.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>As the global health crisis unfolded, many academic conferences moved online in 2020. This move has been hailed as a positive step towards inclusivity in its attenuation of economic, physical, and legal barriers and effectively enabled many individuals from groups that have traditionally been underrepresented to join and participate. A number of studies have outlined how moving online made it possible to gather a more global community and has increased opportunities for individuals with various constraints, e.g., caregiving responsibilities.Yet, the mere existence of online conferences is no guarantee that everyone can attend and participate meaningfully. In fact, many elements of an online conference are still significant barriers to truly diverse participation: the tools used can be inaccessible for some individuals; the scheduling choices can favour some geographical locations; the set-up of the conference can provide more visibility to well-established researchers and reduce opportunities for early-career researchers. While acknowledging the benefits of an online setting, especially for individuals who have traditionally been underrepresented or excluded, we recognize that fostering social justice requires inclusivity to actively be centered in every aspect of online conference design.Here, we draw from the literature and from our own experiences to identify practices that purposefully encourage a diverse community to attend, participate in, and lead online conferences. Reflecting on how to design more inclusive online events is especially important as multiple scientific organizations have announced that they will continue offering an online version of their event when in-person conferences can resume.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Levitis2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Levitis, Elizabeth and van Praag, Cassandra D Gould and Gau, Rémi and Heunis, Stephan and DuPre, Elizabeth and Kiar, Gregory and Bottenhorn, Katherine L and Glatard, Tristan and Nikolaidis, Aki and Whitaker, Kirstie Jane and Mancini, Matteo and Niso, Guiomar and Afyouni, Soroosh and Alonso-Ortiz, Eva and Appelhoff, Stefan and Arnatkeviciute, Aurina and Atay, Selim Melvin and Auer, Tibor and Baracchini, Giulia and Bayer, Johanna M M and Beauvais, Michael J S and Bijsterbosch, Janine D and Bilgin, Isil P and Bollmann, Saskia and Bollmann, Steffen and Botvinik-Nezer, Rotem and Bright, Molly G and Calhoun, Vince D and Chen, Xiao and Chopra, Sidhant and Chuan-Peng, Hu and Close, Thomas G and Cookson, Savannah L and Craddock, R Cameron and De La Vega, Alejandro and De Leener, Benjamin and Demeter, Damion V and Di Maio, Paola and Dickie, Erin W and Eickhoff, Simon B and Esteban, Oscar and Finc, Karolina and Frigo, Matteo and Ganesan, Saampras and Ganz, Melanie and Garner, Kelly G and Garza-Villarreal, Eduardo A and Gonzalez-Escamilla, Gabriel and Goswami, Rohit and Griffiths, John D and Grootswagers, Tijl and Guay, Samuel and Guest, Olivia and Handwerker, Daniel A and Herholz, Peer and Heuer, Katja and Huijser, Dorien C and Iacovella, Vittorio and Joseph, Michael J E and Karakuzu, Agah and Keator, David B and Kobeleva, Xenia and Kumar, Manoj and Laird, Angela R and Larson-Prior, Linda J and Lautarescu, Alexandra and Lazari, Alberto and Legarreta, Jon Haitz and Li, Xue-Ying and Lv, Jinglei and Mansour L., Sina and Meunier, David and Moraczewski, Dustin and Nandi, Tulika and Nastase, Samuel A and Nau, Matthias and Noble, Stephanie and Norgaard, Martin and Obungoloch, Johnes and Oostenveld, Robert and Orchard, Edwina R and Pinho, Ana Lu{\'i}sa and Poldrack, Russell A and Qiu, Anqi and Raamana, Pradeep Reddy and Rokem, Ariel and Rutherford, Saige and Sharan, Malvika and Shaw, Thomas B and Syeda, Warda T and Testerman, Meghan M and Toro, Roberto and Valk, Sofie L and Van Den Bossche, Sofie and Varoquaux, Gaël and Váša, František and Veldsman, Michele and Vohryzek, Jakub and Wagner, Adina S and Walsh, Reubs J and White, Tonya and Wong, Fu-Te and Xie, Xihe and Yan, Chao-Gan and Yang, Yu-Fang and Yee, Yohan and Zanitti, Gaston E and Van Gulick, Ana E and Duff, Eugene and Maumet, Camille}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Centering inclusivity in the design of online conferences—An OHBM–Open Science perspective}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Gigascience}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2047-217X}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1093/gigascience/giab051}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1093/gigascience/giab051}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{giab051}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Research Article</abbr></div> <div id="Pinho2021" class="col-sm-8"> <div class="title">Subject-specific segregation of functional territories based on deep phenotyping</div> <div class="author"> <em>Ana Luísa Pinho</em>, Alexis Amadon, Murielle Fabre, Elvis Dohmatob, Isabelle Denghien, Juan Jesús Torre, Chantal Ginisty, Séverine Becuwe-Desmidt, and <span class="more-authors" title="click to view 13 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '13 more authors' ? 'Séverine Roger, Laurence Laurier, Véronique Joly-Testault, Gaëlle Médiouni-Cloarec, Christine Doublé, Bernadette Martins, Philippe Pinel, Evelyn Eger, Gaël Varoquaux, Christophe Pallier, Stanislas Dehaene, Lucie Hertz-Pannier, Bertrand Thirion' : '13 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">13 more authors</span> </div> <div class="periodical"> <em>Hum Brain Mapp</em> Mar 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1002/hbm.25189" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://onlinelibrary.wiley.com/doi/epdf/10.1002/hbm.25189" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Functional magnetic resonance imaging (fMRI) has opened the possibility to investigatehow brain activity is modulated by behavior. Most studies so far are bound to one singletask, in which functional responses to a handful of contrasts are analyzed and reported asa group average brain map. Contrariwise, recent data-collection efforts have started to tar-get a systematic spatial representation of multiple mental functions. In this paper, weleverage the Individual Brain Charting (IBC) dataset—a high-resolution task-fMRI datasetacquired in a fixed environment—in order to study the feasibility of individual mapping.First, we verify that the IBC brain maps reproduce those obtained from previous, large-scale datasets using the same tasks. Second, we confirm that the elementary spatial com-ponents, inferred across all tasks, are consistently mapped within and, to a lesser extent,across participants. Third, we demonstrate the relevance of the topographic informationof the individual contrast maps, showing that contrasts from one task can be predicted bycontrasts from other tasks. At last, we showcase the benefit of contrast accumulation forthe fine functional characterization of brain regions within a prespecified network. To thisend, we analyze the cognitive profile of functional territories pertaining to the languagenetwork and prove that these profiles generalize across participants.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Pinho2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pinho, Ana Lu{\'i}sa and Amadon, Alexis and Fabre, Murielle and Dohmatob, Elvis and Denghien, Isabelle and Torre, Juan Jes{\'u}s and Ginisty, Chantal and Becuwe-Desmidt, S{\'e}verine and Roger, S{\'e}verine and Laurier, Laurence and Joly-Testault, V{\'e}ronique and M{\'e}diouni-Cloarec, Ga{\"e}lle and Doubl{\'e}, Christine and Martins, Bernadette and Pinel, Philippe and Eger, Evelyn and Varoquaux, Ga{\"e}l and Pallier, Christophe and Dehaene, Stanislas and Hertz-Pannier, Lucie and Thirion, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Subject-specific segregation of functional territories based on deep phenotyping}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Hum Brain Mapp}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{42}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{841-870}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{atlases, brain imaging, cognitive function, data set, functional magnetic resonance imaging}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1002/hbm.25189}</span><span class="p">,</span>
  <span class="na">annotate</span> <span class="p">=</span> <span class="s">{* This paper introduces several key experiments on a fraction of the IBC dataset, namely the first release. In particular, it introduces the application of dictionary learning to summarize contrast maps to topographies. It studies the stability of the dictionary components across data resamplings. It also shows that some contrast maps can be successfully reconstructed from other contrasts. Finally, it illustrates how the accumulation of functional contrasts can help to distinguish between the functional specialization of several regions taken from the language network.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Dataset</abbr></div> <div id="Pinho2021DCa" class="col-sm-8"> <div class="title">IBC</div> <div class="author"> <em>Ana Luísa Pinho</em>, L. Hertz-Pannier, and B. Thirion</div> <div class="periodical"> <em>OpenNeuro</em> January 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.18112/openneuro.ds002685.v1.3.1" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>Overview: Functional Magnetic Resonance Imaging (fMRI) has opened the door to brain mapping of perceptual, motor, or cognitive functions. As such, it provides an instrumental basis for the whole field of cognitive neuroimag- ing. However, there exists to date no data collection that systematically maps representations for a wide-variety of mental functions at a fine spa- tial scale. The Individual Brain Charting (IBC) project is collecting a high-resolution multi-task-fMRI dataset, to provide an objective basis for a comprehensive atlas of brain responses. The data refer to a cohort of twelve participants performing many different tasks. Acquiring a large amount of tasks on the same subjects yields a precise mapping of the underlying functions, free from both inter-subject and inter-site variability. Additionally, the dataset comes with high-resolution anatomical and diffusion images, to achieve a fine anatomical characterization of these brains.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Pinho2021DCa</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pinho, Ana Lu{\'i}sa and Hertz-Pannier, L. and Thirion, B.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{IBC}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{OpenNeuro}}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{{ds002685}}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{{January}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.18112/openneuro.ds002685.v1.3.1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Dataset</abbr></div> <div id="Pinho2021DCb" class="col-sm-8"> <div class="title">Individual Brain Charting (IBC) v3.0</div> <div class="author"> A. L. Pinho, S. Shankar, H. Richard, A. Amadon, S. Nishimoto, A. G. Huth, M. Eickenberg, I. Denghien, and <span class="more-authors" title="click to view 18 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '18 more authors' ? 'J. J. Torre, H. Aggarwal, C. Ginisty, S. Becuwe-Desmidt, S. Roger, Y. Lecomte, V. Berland, L. Laurier, V. Joly-Testault, G. Médiouni-Cloarec, C. Doublé, B. Martins, J. V. Haxby, J. Gallant, G. Varoquaux, S. Dehaene, L. Hertz-Pannier, B. Thirion' : '18 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">18 more authors</span> </div> <div class="periodical"> <em>EBRAINS</em> September 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.25493/SM37-TS4" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>Functional Magnetic Resonance Imaging (fMRI) has opened the door to brain mapping of perceptual, motor, or cognitive functions. As such, it provides an instrumental basis for the whole field of cognitive neuroimaging. However, there exists to date no data collection that systematically maps representations for a wide-variety of mental functions at a fine spatial scale. The Individual Brain Charting (IBC) project is collecting a high-resolution multi-task-fMRI dataset to provide an objective basis for a comprehensive atlas of brain responses. The data refer to a cohort of participants performing many different tasks. Acquiring a large amount of tasks on the same subjects yields a precise mapping of the underlying functions, free from both inter-subject and inter-site variability. Additionally, the dataset comes with high-resolution anatomical and diffusion images, to achieve a fine anatomical characterization of these brains.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Pinho2021DCb</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pinho, A. L. and Shankar, S. and Richard, H. and Amadon, A. and Nishimoto, S. and Huth, A. G. and Eickenberg, M. and Denghien, I. and Torre, J. J. and Aggarwal, H. and Ginisty, C. and Becuwe-Desmidt, S. and Roger, S. and Lecomte, Y. and Berland, V. and Laurier, L. and Joly-Testault, V. and M{\'e}diouni-Cloarec, G. and Doubl{\'e}, C. and Martins, B. and Haxby, J. V. and Gallant, J. and Varoquaux, G. and Dehaene, S. and Hertz-Pannier, L. and Thirion, B.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Individual Brain Charting (IBC) v3.0}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{EBRAINS}}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{{September}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.25493/SM37-TS4}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Review</abbr></div> <div id="Thirion2021" class="col-sm-8"> <div class="title">From deep brain phenotyping to functional atlasing</div> <div class="author"> Bertrand Thirion, Alexis Thual, and <em>Ana Luísa Pinho</em> </div> <div class="periodical"> <em>Curr Opin Behav Sci</em> Aug 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1016/j.cobeha.2021.05.004" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>How can neuroimaging inform us about the function of brain structures? This simple question immediately brings out two pertinent issues: Firstly, an inference problem, namely the fact that the function of a region can only be asserted after observing a large array of experimental conditions or contrasts; and second, the fact that the identity of a region can only be defined with accuracy at the individual level, because of intrinsic differences between subjects. To overcome this double challenge, we consider an approach based on the deep phenotyping of behavioral responses from task data acquired using functional magnetic resonance imaging. The concept of functional fingerprint—which subsumes the accumulation of functional information at a given brain location—is herein discussed in detail through concrete examples taken from the Individual Brain Charting dataset.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Thirion2021</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{From deep brain phenotyping to functional atlasing}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Curr Opin Behav Sci}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{40}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{201-212}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Deep Imaging - Personalized Neuroscience}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2352-1546}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.cobeha.2021.05.004}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S2352154621001121}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Thirion, Bertrand and Thual, Alexis and Pinho, Ana Lu{\'i}sa}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Data Descriptor</abbr></div> <div id="Pinho2020" class="col-sm-8"> <div class="title">Individual Brain Charting dataset extension, second release of high-resolution fMRI data for cognitive mapping</div> <div class="author"> <em>Ana Luísa Pinho</em>, Alexis Amadon, Baptiste Gauthier, Nicolas Clairis, André Knops, Sarah Genon, Elvis Dohmatob, Juan Jesús Torre, and <span class="more-authors" title="click to view 20 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '20 more authors' ? 'Chantal Ginisty, Séverine Becuwe-Desmidt, Séverine Roger, Yann Lecomte, Valérie Berland, Laurence Laurier, Véronique Joly-Testault, Gaëlle Médiouni-Cloarec, Christine Doublé, Bernadette Martins, Eric Salmon, Manuela Piazza, David Melcher, Mathias Pessiglione, Virginie Van Wassenhove, Evelyn Eger, Gaël Varoquaux, Stanislas Dehaene, Lucie Hertz-Pannier, Bertrand Thirion' : '20 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">20 more authors</span> </div> <div class="periodical"> <em>Sci Data</em> Oct 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1038/s41597-020-00670-4" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/s41597-020-00670-4-1.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>We present an extension of the Individual Brain Charting dataset –a high spatial-resolution, multi-task, functional Magnetic Resonance Imaging dataset, intended to support the investigation on the functional principles governing cognition in the human brain. The concomitant data acquisition from the same 12 participants, in the same environment, allows to obtain in the long run finer cognitive topographies, free from inter-subject and inter-site variability. This second release provides more data from psychological domains present in the first release, and also yields data featuring new ones. It includes tasks on e.g. mental time travel, reward, theory-of-mind, pain, numerosity, self-reference effect and speech recognition. In total, 13 tasks with 86 contrasts were added to the dataset and 63 new components were included in the cognitive description of the ensuing contrasts. As the dataset becomes larger, the collection of the corresponding topographies becomes more comprehensive, leading to better brain-atlasing frameworks. This dataset is an open-access facility; raw data and derivatives are publicly available in neuroimaging repositories.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Pinho2020</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pinho, Ana Lu{\'i}sa and Amadon, Alexis and Gauthier, Baptiste and Clairis, Nicolas and Knops, Andr{\'e} and Genon, Sarah and Dohmatob, Elvis and Jes{\'u}s Torre, Juan and Ginisty, Chantal and Becuwe-Desmidt, S{\'e}verine and Roger, S{\'e}verine and Lecomte, Yann and Berland, Val{\'e}rie and Laurier, Laurence and Joly-Testault, V{\'e}ronique and M{\'e}diouni-Cloarec, Ga{\"e}lle and Doubl{\'e}, Christine and Martins, Bernadette and Salmon, Eric and Piazza, Manuela and Melcher, David and Pessiglione, Mathias and Van Wassenhove, Virginie and Eger, Evelyn and Varoquaux, Ga{\"e}l and Dehaene, Stanislas and Hertz-Pannier, Lucie and Thirion, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Individual Brain Charting dataset extension, second release of high-resolution fMRI data for cognitive mapping}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{Sci Data}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/s41597-020-00670-4}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Dataset</abbr></div> <div id="Pinho2020DCa" class="col-sm-8"> <div class="title">Individual Brain Charting dataset extension, second release of high-resolution fMRI data for cognitive mapping</div> <div class="author"> <em>Ana Luísa Pinho</em>, A. Amadon, T. Ruest, M. Fabre, B. Gauthier, N. Clairis, A. Knops, S. Genon, and <span class="more-authors" title="click to view 25 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '25 more authors' ? 'E. Dohmatob, I. Denghien, J.J. Torre, C. Ginisty, S. Becuwe-Desmidt, S. Roger, Y. Lecomte, V. Berland, L. Laurier, V. Joly-Testault, G. Médiouni-Cloarec, C. Doublé, B. Martins, E. Salmon, M. Piazza, D. Melcher, M. Pessiglione, V. Wassenhove, P. Pinel, E. Eger, G. Varoquaux, C. Pallier, S. Dehaene, L. Hertz-Pannier, B. Thirion' : '25 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">25 more authors</span> </div> <div class="periodical"> <em>NeuroVault</em> Oct 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://identifiers.org/neurovault.collection:6618" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>The individual Brain Charting (IBC) Project is using high resolution fMRI to map 13 subjects that undergo a large number of tasks: the HCP tasks, the so-called ARCHI tasks, a specific language task, video watching, low-level visual stimulation etc. The native resolution of the data is 1.5mm isotropic. Their main value lies in the large number of contrasts probed, the level of detail and the high SNR per subject. This dataset is meant to provide the basis of a functional brain atlas. We upload here smoothed individual SPMs. The uploaded maps comprise session-specific and fixed effects across maps acquired with AP and PA phase encoding directions. Note that Neurovault collection #4438 is a subset of that one. In the present collections, some details have been fixed, including mroe accurate and unique file naming.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Pinho2020DCa</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pinho, Ana Lu{\'i}sa and Amadon, A. and Ruest, T. and Fabre, M. and Gauthier, B. and Clairis, N. and Knops, A. and Genon, S. and Dohmatob, E. and Denghien, I. and Torre, J.J. and Ginisty, C. and Becuwe-Desmidt, S. and Roger, S. and Lecomte, Y. and Berland, V. and Laurier, L. and Joly-Testault, V. and M{\'e}diouni-Cloarec, G. and Doubl{\'e}, C. and Martins, B. and Salmon, E. and Piazza, M. and Melcher, D. and Pessiglione, M. and van Wassenhove, V. and Pinel, P. and Eger, E. and Varoquaux, G. and Pallier, C. and Dehaene, S. and Hertz-Pannier, L. and Thirion, B.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Individual Brain Charting dataset extension, second release of high-resolution fMRI data for cognitive mapping}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{NeuroVault}}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{{id collection=6618}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://identifiers.org/neurovault.collection:6618}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Preprint</abbr></div> <div id="Richard2019" class="col-sm-8"> <div class="title">Fast shared response model for fMRI data</div> <div class="author"> Hugo Richard, Lucas Martin, <em>Ana Luísa Pinho</em>, Jonathan W. Pillow, and Bertrand Thirion</div> <div class="periodical"> <em>CoRR</em> Dec 2019 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.48550/arXiv.1909.12537" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/1909.12537.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The shared response model provides a simple but effective framework to analyse fMRI data of subjects exposed to naturalistic stimuli. However when the number of subjects or runs is large, fitting the model requires a large amount of memory and computational power, which limits its use in practice. In this work, we introduce the FastSRM algorithm that relies on an intermediate atlas-based representation. It provides considerable speed-up in time and memory usage, hence it allows easy and fast large-scale analysis of naturalistic-stimulus fMRI data. Using four different datasets, we show that our method matches the performance of the original SRM algorithm while being about 5x faster and 20x to 40x more memory efficient. Based on this contribution, we use FastSRM to predict age from movie watching data on the CamCAN sample. Besides delivering accurate predictions (mean absolute error of 7.5 years), FastSRM extracts topographic patterns that are predictive of age, demonstrating that brain activity during free perception reflects age.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Richard2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Richard, Hugo and Martin, Lucas and Pinho, Ana Lu{\'i}sa and Pillow, Jonathan W. and Thirion, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fast shared response model for fMRI data}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{CoRR}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{abs/1909.12537}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">eprinttype</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{1909.12537}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Mon, 29 Aug 2022 09:33:25 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/journals/corr/abs-1909-12537.bib}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Editorial</abbr></div> <div id="Schrouff2019" class="col-sm-8"> <div class="title">Gender bias in (neuro) science: facts, consequences, and solutions</div> <div class="author"> Jessica Schrouff, Doris Pischedda, Sarah Genon, Gregory Fryns, Ana Luísa Pinho, Eliana Vassena, Antonietta G Liuzzi, and F Santos Ferreira</div> <div class="periodical"> <em>Eur J Neurosci</em> Feb 2019 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1111/ejn.14397" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://onlinelibrary.wiley.com/doi/epdf/10.1111/ejn.14397" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Schrouff2019</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Gender bias in (neuro) science: facts, consequences, and solutions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Schrouff, Jessica and Pischedda, Doris and Genon, Sarah and Fryns, Gregory and Lu{\'i}sa Pinho, Ana and Vassena, Eliana and Liuzzi, Antonietta G and Santos Ferreira, F}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Eur J Neurosci}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{50}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3094--3100}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Blackwell Publishing}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1111/ejn.14397}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Book Chapter</abbr></div> <div id="Pinho2018" class="col-sm-8"> <div class="title">The Neuropsychological Aspects of Musical Creativity</div> <div class="author"> <em>Ana Luísa Pinho</em> </div> <div class="periodical"> Aug 2018 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1007/978-3-319-76054-4_4" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>Creativity emerges from the individual or collective intellect, in order to unfold the conundrum of life and give rise to meaningful deliberations for the attainment of a flourishing life. More specifically, creativity is commonly defined, within the framework of psychology, as an act or product that shall fulfill three main criteria: originality, unexpectedness, and usefulness. The cognitive science approach to creativity investigates the intellectual processes and representations concerned with the creative thinking. The methodologies of cognitive science, derived from the technological advancements of the past sixty years, have begun to adopt a more definitive and systemic perspective. Neuroscience has emerged, under this context, as the scientific study dedicated to explore the biological substrates of the nervous system, by utilizing a multitude of techniques such as neuroimaging. Cognitive neuroscience, in particular, studies the neural correlates of mental processes, and it constitutes the central approach herein adopted to examine musical creativity as a product of the human mind. In the present section, a definition plus historical evolvement of creativity are firstly provided together with an overview of its developments in psychometry. Secondly, a comprehensive description regarding the scientific advances about the topic, and within the field of cognitive neuroscience, is described according to: (1) the model on the four types of creativity and (2) the main categories of experimental designs implemented so far. Lastly, the latest advancements on the study of musical creativity, in particular musical improvisation, will be addressed under the neuroimaging framework.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inbook</span><span class="p">{</span><span class="nl">Pinho2018</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pinho, Ana Lu{\'i}sa}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Kapoula, Zo{\"i} and Volle, Emmanuelle and Renoult, Julien and Andreatta, Moreno}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Neuropsychological Aspects of Musical Creativity}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Exploring Transdisciplinarity in Art and Sciences}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer International Publishing}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Cham}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{77--103}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-319-76054-4}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-76054-4_4}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-76054-4_4}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Data Descriptor</abbr></div> <div id="Pinho2019" class="col-sm-8"> <div class="title">Individual Brain Charting, a high-resolution fMRI dataset for cognitive mapping</div> <div class="author"> <em>Ana Luísa Pinho</em>, Alexis Amadon, Torsten Ruest, Murielle Fabre, Elvis Dohmatob, Isabelle Denghien, Chantal Ginisty,  Séverine-Becuwe, and <span class="more-authors" title="click to view 13 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '13 more authors' ? 'Séverine Roger, Laurence Laurier, Véronique Joly-Testault, Gaëlle Médiouni-Cloarec, Christine Doublé, Bernadette Martins, Philippe Pinel, Evelyn Eger, Gaël Varoquaux, Christophe Pallier, Stanislas Dehaene, Lucie Hertz-Pannier, Bertrand Thirion' : '13 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">13 more authors</span> </div> <div class="periodical"> <em>Sci Data</em> Jun 2018 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1038/sdata.2018.105" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/sdata2018105.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Functional Magnetic Resonance Imaging (fMRI) has furthered brain mapping on perceptual, motor, as well as higher-level cognitive functions. However, to date, no data collection has systematically addressed the functional mapping of cognitive mechanisms at a fine spatial scale. The Individual Brain Charting (IBC) project stands for a high-resolution multi-task fMRI dataset that intends to provide the objective basis toward a comprehensive functional atlas of the human brain. The data refer to a cohort of 12 participants performing many different tasks. The large amount of task-fMRI data on the same subjects yields a precise mapping of the underlying functions, free from both inter-subject and inter-site variability. The present article gives a detailed description of the first release of the IBC dataset. It comprises a dozen of tasks, addressing both low- and high- level cognitive functions. This openly available dataset is thus intended to become a reference for cognitive brain mapping.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Pinho2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pinho, Ana Lu{\'i}sa and Amadon, Alexis and Ruest, Torsten and Fabre, Murielle and Dohmatob, Elvis and Denghien, Isabelle and Ginisty, Chantal and S{\'e}verine-Becuwe and Roger, S{\'e}verine and Laurier, Laurence and Joly-Testault, V{\'e}ronique and M{\'e}diouni-Cloarec, Ga{\"e}lle and Doubl{\'e}, Christine and Martins, Bernadette and Pinel, Philippe and Eger, Evelyn and Varoquaux, Ga{\"e}l and Pallier, Christophe and Dehaene, Stanislas and Hertz-Pannier, Lucie and Thirion, Bertrand}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Individual {B}rain {C}harting, a high-resolution f{MRI} dataset for cognitive mapping}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Sci Data}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{180105}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/sdata.2018.105}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Conference Paper</abbr></div> <div id="Richard2018" class="col-sm-8"> <div class="title">Optimizing deep video representation to match brain activity</div> <div class="author"> Hugo Richard, <em>Ana Luísa Pinho</em>, Bertrand Thirion, and Guillaume Charpiat</div> <div class="periodical"> <em>In CCN 2018 - Conference on Cognitive Computational Neuroscience</em> Sep 2018 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.48550/arXiv.1809.02440" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://hal.archives-ouvertes.fr/hal-01868735/file/main.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The comparison of observed brain activity with the statistics generated by artificial intelligence systems is useful to probe brain functional organization under ecological conditions. Here we study fMRI activity in ten subjects watching color natural movies and compute deep representations of these movies with an architecture that relies on optical flow and image content. The association of activity in visual areas with the different layers of the deep architecture displays complexity-related contrasts across visual areas and reveals a striking foveal/peripheral dichotomy.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Richard2018</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Optimizing deep video representation to match brain activity}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Richard, Hugo and Pinho, Ana Lu{\'i}sa and Thirion, Bertrand and Charpiat, Guillaume}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.archives-ouvertes.fr/hal-01868735}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{CCN 2018 - Conference on Cognitive Computational Neuroscience}}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Philadelphia, United States}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{video encoding ; brain mapping ; deep learning}</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-01868735}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2015</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Research Article</abbr></div> <div id="Pinho2015" class="col-sm-8"> <div class="title">Addressing a paradox: dual strategies for creative performance in introspective and extrospective networks</div> <div class="author"> <em>Ana Luísa Pinho</em>, Fredrik Ullén, Miguel Castelo-Branco, Peter Fransson, and Örjan Manzano</div> <div class="periodical"> <em>Cereb Cortex</em> Jun 2015 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1093/cercor/bhv130" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://watermark.silverchair.com/bhv130.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA1QwggNQBgkqhkiG9w0BBwagggNBMIIDPQIBADCCAzYGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMGmBn5iwRMVDUNvQ6AgEQgIIDB8BK6QoB0qs4n2OA3qGm80vR8yC-URIfWaUpfEs-Bbw3qSGMfVgBzffcqQD3ssmTRQ_PJOPIYkNznmIa7nLSj5LMNjRZ79EDEbOC7p6qtY5SquFnlhkriJcjOBRdfzfu2CqPQ5nLP5H2QWHAcMtFxZsf6Z2VPx-Z-MYj_lThbSr7lGRjv7tZUvsev8cZMyC3xN-KRiAdbOCREgoyjjeh9amB26tMtCajCiOmRYR2oSYqbuOEJSxs3xfHgy3HTwL6eVg1X3b-wpPLiDe9rB8d0_50WvHGeygEs7p4y4ShB2YNMrHUFTcW5ivSCX7qk5qWG4naKopQPfSacjrZRxQgC5q4dioNDw1hpNr0tYRO4tCo1oyfyFf5O6S_TFLmfM5j2hapKrsOw04QjU6cbAYHJsnPmqF1XCxg9lebU9_MMZ0QjzbCAhAYj_LYDB9luJxiWrBjbPZYmn2Jf52bVmL4kqui87sjVCO0uCFBPiOCm3Qf7eWZFjFkme-23nKZ-cQpBNRlGaBZijWPoRBGVyWaHtH_ob2BdaPsu0PyVD4619PNLrrgw4OvbO6gcj7HS32i6E50r1G6moVbEF5Hodxm0AM-SUWw9XjftTPyaSu-iROjzL1IgyhM-ZTaOnnIVzGNjmAVzrGLt-9ZRBwlW7qpuDp1JXAWsER6F0qW0y0B5RDiTYQQ9ZdMdCxCTSMP4raGE6lcgFqSmEi0J6wmMg1gP9Y-68Y3EWnYcBBXFo7wXXCgojS9bCLlAxZ5oB4rtI01Wewt1pOoQETZ469qjQnw_YWhGxJ69_OMwTTDwao104aR-dEeOo-LUMjehrkdHq64dDJWeuYAXrJJ1M5RrqVvStBfcnTTawh23Jz4FuImPl6zi1XPMxIy_TfbmqVSkl5lI-7djOkhH1cbbuJG-cbnPcjG1YSTt3OK-rGCFTBfp-SwavM766IjXltV6nwrenL0vi0DN5rnMQMySTAb00905tzr4No_aFqC6DeY4a-krjqy1iTnRwLeTGFH4G6mfX42pWTqkdooOz4" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Neuroimaging studies of internally generated behaviors have shown seemingly paradoxical results regarding the dorsolateral prefrontal cortex (DLPFC), which has been found to activate, not activate or even deactivate relative to control conditions. On the one hand, the DLPFC has been argued to exert top–down control over generative thought by inhibiting habitual responses; on the other hand, a deactivation and concomitant decrease in monitoring and focused attention has been suggested to facilitate spontaneous associations and novel insights. Here, we demonstrate that prefrontal engagement in creative cognition depends dramatically on experimental conditions, that is, the goal of the task. We instructed professional pianists to perform improvisations on a piano keyboard during fMRI and play, either with a certain emotional content (happy/fearful), or using certain keys (tonal/atonal pitch-sets). We found lower activity in primarily the right DLPFC, dorsal premotor cortex and inferior parietal cortex during emotional conditions compared with pitch-set conditions. Furthermore, the DLPFC was functionally connected to the default mode network during emotional conditions and to the premotor network during pitch-set conditions. The results thus support the notion of two broad cognitive strategies for creative problem solving, relying on extrospective and introspective neural circuits, respectively.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Pinho2015</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Addressing a paradox: dual strategies for creative performance in introspective and extrospective networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pinho, Ana Lu{\'i}sa and Ull{\'e}n, Fredrik and Castelo-Branco, Miguel and Fransson, Peter and de Manzano, {\"O}rjan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Cereb Cortex}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{26}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3052--3063}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Oxford University Press}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1093/cercor/bhv130}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2014</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Research Article</abbr></div> <div id="Pinho2014" class="col-sm-8"> <div class="title">Connecting to create: expertise in musical improvisation is associated with increased functional connectivity between premotor and prefrontal areas</div> <div class="author"> <em>Ana Luísa Pinho</em>, Örjan Manzano, Peter Fransson, Helene Eriksson, and Fredrik Ullén</div> <div class="periodical"> <em>J Neurosci</em> Apr 2014 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1523/JNEUROSCI.4769-13.2014" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://www.jneurosci.org/content/jneuro/34/18/6156.full.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Musicians have been used extensively to study neural correlates of long-term practice, but no studies have investigated the specific effects of training musical creativity. Here, we used human functional MRI to measure brain activity during improvisation in a sample of 39 professional pianists with varying backgrounds in classical and jazz piano playing. We found total hours of improvisation experience to be negatively associated with activity in frontoparietal executive cortical areas. In contrast, improvisation training was positively associated with functional connectivity of the bilateral dorsolateral prefrontal cortices, dorsal premotor cortices, and presupplementary areas. The effects were significant when controlling for hours of classical piano practice and age. These results indicate that even neural mechanisms involved in creative behaviors, which require a flexible online generation of novel and meaningful output, can be automated by training. Second, improvisational musical training can influence functional brain properties at a network level. We show that the greater functional connectivity seen in experienced improvisers may reflect a more efficient exchange of information within associative networks of importance for musical creativity.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Pinho2014</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Connecting to create: expertise in musical improvisation is associated with increased functional connectivity between premotor and prefrontal areas}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pinho, Ana Lu{\'i}sa and de Manzano, {\"O}rjan and Fransson, Peter and Eriksson, Helene and Ull{\'e}n, Fredrik}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{J Neurosci}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6156--6163}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Society for Neuroscience}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1523/JNEUROSCI.4769-13.2014}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 Ana Luísa Pinho. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Last updated: February 26, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> </body> </html>